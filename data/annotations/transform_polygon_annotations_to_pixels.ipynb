{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import rasterio\n",
        "from nso_ds_classes.nso_ds_normalize_scaler import scaler_class_all\n",
        "from annotations.data_preparation import extract_dataframe_pixels_values_from_tif_and_polygons\n",
        "from annotations.utils import get_scaler_filepath\n",
        "from annotations.data_loader import load_annotations_polygons, load_annotations_polygons_gpkg\n",
        "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
        "import os\n",
        "import settings_blob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# function to upload the annotations to the cloud.\n",
        "def upload_to_blob(apath, directory_blob=\"\"):\n",
        "\n",
        "    container_name = \"satellite-images-nso\"\n",
        "    blob_name = directory_blob+os.path.basename(apath) \n",
        "\n",
        "\n",
        "    blob_service_client = BlobServiceClient.from_connection_string(settings_blob.connection_string)\n",
        "    container_client = blob_service_client.get_container_client(container_name)\n",
        "    blob_client = container_client.get_blob_client(blob_name)\n",
        "\n",
        "    with open(apath, \"rb\") as data:\n",
        "            blob_client.upload_blob(data ,  overwrite=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transform Polygon Annotations to Pixel Annotation Parquet files\n",
        "\n",
        "This script is intended to transform given polygon annotations in geojson (made in i.e. QGis) into pixel level annotations, with scaled band values. The pixel level annotations are written to parquet files.\n",
        "Change the variables below to match the situation on your device.\n",
        "Note that these transformations are quite quickly very memory intensive.\n",
        "\n",
        "Date: 2024-01-11 \\\n",
        "Author: Pieter Kouyzer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set variables\n",
        "location = \"Voornes_Duin\"\n",
        "\n",
        "if location == \"Voornes_Duin\":\n",
        "    satellite = \"PNEO\"\n",
        "    images_folder = \"E:/Data/remote_sensing/satellite-images/PNEO_30CM/Voornes Duincv /\"\n",
        "    regex = \"*_height_asphalt_crop.tif\"\n",
        "    annotations_folder = \"C:/Users/pzhadmin/Data/remote-sensing/annotations/\"\n",
        "    annotations_polygon_filename_regex = \"Voornes Duin PNEO_30CM Annotations_2024-01-19.geojson\"\n",
        "    scaler_folder_path = \"../../scalers/\"\n",
        "    col_names = [\"r\", \"g\", \"b\", \"n\", \"e\", \"d\", \"ndvi\", \"re_ndvi\", \"height\"]\n",
        "    pixel_filepath = os.path.join(annotations_folder, f\"{location}_{satellite}_pixel_annotations.parquet\")\n",
        "    pixel_scaled_filepath = os.path.join(annotations_folder, f\"{location}_{satellite}_pixel_annotations_scaled.parquet\")\n",
        "\n",
        "elif location == \"Coepelduynen\":\n",
        "   \n",
        "    images_folder = \"E:/data/\"\n",
        "    regex = f\"{location}/2023*re*asphalt_crop.tif\"\n",
        "    annotations_path = \"C:/repos/satellite-images-nso-datascience/data/annotations/Coepelduynen/Annotations_Coepelduynen_2023.gpkg\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if location == \"Voornes_Duin\":\n",
        "    annotations_polygons_gdf = load_annotations_polygons(annotations_folder, annotations_polygon_filename_regex, regex, images_folder)\n",
        "\n",
        "elif location == \"Coepelduynen\":\n",
        "    annotations_polygons_gdf = load_annotations_polygons_gpkg(\"C:/repos/satellite-images-nso-datascience/data/annotations/Coepelduynen/Annotations_Coepelduynen_2023.gpkg\")\n",
        "    annotations_polygons_gdf = annotations_polygons_gdf.reset_index(drop=True)\n",
        "    # Custom actions to set data straight.\n",
        "    annotations_polygons_gdf.loc[annotations_polygons_gdf[\"name\"] != \"Annotations_Coepelduynen_2023\",\"label\"] = annotations_polygons_gdf[annotations_polygons_gdf[\"name\"] != \"Annotations_Coepelduynen_2023\"][\"Label_name\"]\n",
        "    annotations_polygons_gdf = annotations_polygons_gdf.drop([\"Label_name\"], axis=1)\n",
        "    annotations_polygons_gdf['label'] = annotations_polygons_gdf['label'].str.replace(\"\\nAsphalt\",\"Asphalt\")\n",
        "    annotations_polygons_gdf[\"Label\"] = annotations_polygons_gdf[\"label\"]\n",
        "    annotations_polygons_gdf = annotations_polygons_gdf.drop([\"label\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if location == \"Voornes_Duin\":\n",
        "    if os.path.isfile(pixel_filepath):\n",
        "        df = pd.read_parquet(pixel_filepath)\n",
        "    else:\n",
        "        dfs = []\n",
        "        for tif_file in glob.glob(os.path.join(images_folder, regex)):\n",
        "            tif_file = tif_file.replace(\"\\\\\",\"/\")\n",
        "            print(tif_file)\n",
        "            name_tif_file = tif_file.split(\"/\")[-1].split(\".\")[0]\n",
        "            with rasterio.open(tif_file) as dataset:\n",
        "                dfs += [\n",
        "                    extract_dataframe_pixels_values_from_tif_and_polygons(\n",
        "                        tif_dataset=dataset, polygon_gdf=annotations_polygons_gdf,name_tif_file=name_tif_file\n",
        "                    )\n",
        "                ]\n",
        "            \n",
        "        df = pd.concat(dfs)\n",
        "        df.to_parquet(pixel_filepath)\n",
        "\n",
        "elif location == \"Coepelduynen\":\n",
        "    #Custom aggregation for annnotations across all satellite images\n",
        "    dfs = []\n",
        "    for tif_file in glob.glob(os.path.join(images_folder, regex)):\n",
        "            tif_file = tif_file.replace(\"\\\\\",\"/\")\n",
        "            print(tif_file)\n",
        "            name_tif_file = tif_file.split(\"/\")[-1].split(\".\")[0]\n",
        "            with rasterio.open(tif_file) as dataset:\n",
        "                dfs += [\n",
        "                extract_dataframe_pixels_values_from_tif_and_polygons(\n",
        "                            tif_dataset=dataset,\n",
        "                            polygon_gdf=annotations_polygons_gdf[\n",
        "                                annotations_polygons_gdf[\"name\"] == \"Annotations_Coepelduynen_2023\"\n",
        "                            ],\n",
        "                            name_tif_file=tif_file.split(\"/\")[-1],\n",
        "                            name_annotations=\"Annotations_Coepelduynen_2023\",\n",
        "                        )          \n",
        "                ]\n",
        "            \n",
        "    df = pd.concat(dfs)\n",
        "\n",
        "    # Annotations for specific satellite images\n",
        "    dfs = []\n",
        "    for tif_file in glob.glob(os.path.join(images_folder, regex)):\n",
        "        tif_file = tif_file.replace(\"\\\\\",\"/\")\n",
        "        print(tif_file)\n",
        "        name_tif_file = tif_file.split(\"/\")[-1].split(\".\")[0].split(\"_\")[0]+\"_annotations\"\n",
        "        print(name_tif_file)\n",
        "        with rasterio.open(tif_file) as dataset:\n",
        "                dfs += [\n",
        "                extract_dataframe_pixels_values_from_tif_and_polygons(\n",
        "                            tif_dataset=dataset,\n",
        "                            polygon_gdf=annotations_polygons_gdf[\n",
        "                                annotations_polygons_gdf[\"name\"] == name_tif_file\n",
        "                            ],\n",
        "                            name_tif_file=tif_file.split(\"/\")[-1],\n",
        "                            name_annotations=name_tif_file,\n",
        "                        )          \n",
        "                ]\n",
        "        \n",
        "    \n",
        "    dfs = pd.concat(dfs)\n",
        "    df = pd.concat([dfs,df])\n",
        "    \n",
        "    # Extra check to see if all the correct bands are found\n",
        "    #if \"ndvi\" not in df.columns:\n",
        "\n",
        "    #    if \"n\" in df.columns:\n",
        "    #        df['ndvi'] =df.apply(lambda x:(((x['n'] - x['r']) / (x['n'] + x['r']))*100) + 100, axis =1)\n",
        "    #    if \"i\" in df.columns:\n",
        "    #        df['ndvi'] =df.apply(lambda x:(((x['i'] - x['r']) / (x['i'] + x['r']))*100) + 100, axis =1)\n",
        "    #    else:\n",
        "    #        print(\"No infrared band found for ndvi\")\n",
        "\n",
        "    #if \"ndwi\" not in df.columns:\n",
        "    #    if \"n\" in df.columns:\n",
        "    #        df['ndwi'] = df.apply(lambda x: ((x['g']- x['n'])/(x['n']+x['g'])*100)+100, axis=1 )\n",
        "    #    if \"i\" in df.columns:\n",
        "    #        df['ndwi'] = df.apply(lambda x: ((x['g']- x['i'])/(x['i']+x['g'])*100)+100, axis=1 )\n",
        "    #    else:\n",
        "    #        print(\"No infrared band found for ndwi\")\n",
        "\n",
        "    #if \"re_ndvi\" not in df.columns:\n",
        "    #    if \"e\" in df.columns:\n",
        "    #        df['re_ndvi'] =df.apply(lambda x:(((x['e'] - x['r']) / (x['e'] + x['r']))*100) + 100, axis =1)\n",
        "    #    else:\n",
        "    #        print(\"\")\n",
        "\n",
        "    df.to_parquet(\"annotations_pixel_dataframes/annotaties_coepelduynen_to_pixel_2023.parquet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Nieuwkoopse Plassen annotations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "annotation_folder_path = \"C:/repos/satellite-images-nso-datascience/data/annotations/Schippergat/{to_replace}*.geojson\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PNEO annotations\n",
        "dfs = []\n",
        "for annotation_file in glob.glob(annotation_folder_path.replace(\"{to_replace}\", \"2023\")):\n",
        "    annotation_file = annotation_file.replace(\"\\\\\",\"/\")\n",
        "    print(annotation_file)\n",
        "\n",
        "    tif_file = glob.glob(\"E:/data/nieuwkoopse_plassen_schippersgat/\"+annotation_file.split(\"/\")[-1].split(\"_\")[0]+\"*\")[0].replace(\"\\\\\",\"/\")\n",
        "    print(tif_file)\n",
        "\n",
        "    name_tif_file = tif_file.split(\"/\")[-1].split(\".\")[0].split(\"_\")[0]+\"_annotations\"\n",
        "    print(name_tif_file)\n",
        "\n",
        "    waterplanten_annotations = gpd.read_file(annotation_file)\n",
        "    waterplanten_annotations[\"name\"] = name_tif_file\n",
        "    try: \n",
        "        waterplanten_annotations[\"Label\"] = waterplanten_annotations[\"class\"]\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "    waterplanten_annotations  = waterplanten_annotations.to_crs(\"EPSG:28992\")\n",
        "\n",
        "    \n",
        "    with rasterio.open(tif_file) as dataset:\n",
        "         dfs += [extract_dataframe_pixels_values_from_tif_and_polygons(dataset, waterplanten_annotations, tif_file.split(\"/\")[-1], name_tif_file)]\n",
        "\n",
        "df = pd.concat(dfs)\n",
        "# TODO: update the descriptions\n",
        "#df['ndwi'] =df['height']\n",
        "#df = df.drop(['height'], axis=1)\n",
        "df.to_parquet(\"./annotations_pixel_dataframes/PNEO_waterplanten_annotations.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload annotations to the cloud\n",
        "upload_to_blob(\"./annotations_pixel_dataframes/PNEO_waterplanten_annotations.parquet\", \"Schippersgat/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Superview annotations\n",
        "dfs = []\n",
        "for annotation_file in glob.glob(annotation_folder_path.replace(\"{to_replace}\", \"2022\"))+  glob.glob(annotation_folder_path.replace(\"{to_replace}\", \"2021\"))+  glob.glob(annotation_folder_path.replace(\"{to_replace}\", \"2019\")):\n",
        "    annotation_file = annotation_file.replace(\"\\\\\",\"/\")\n",
        "    print(annotation_file)\n",
        "\n",
        "    tif_file = glob.glob(\"E:/data/nieuwkoopse_plassen_schippersgat/\"+annotation_file.split(\"/\")[-1].split(\"_\")[0]+\"*\")[0].replace(\"\\\\\",\"/\")\n",
        "    print(tif_file)\n",
        "\n",
        "    name_tif_file = tif_file.split(\"/\")[-1].split(\".\")[0].split(\"_\")[0]+\"_annotations\"\n",
        "    print(name_tif_file)\n",
        "\n",
        "    waterplanten_annotations = gpd.read_file(annotation_file)\n",
        "    waterplanten_annotations[\"name\"] = name_tif_file\n",
        "\n",
        "    if \"label\" in waterplanten_annotations.columns:\n",
        "        waterplanten_annotations[\"Label\"] = waterplanten_annotations[\"label\"]\n",
        "\n",
        "    try: \n",
        "        waterplanten_annotations[\"Label\"] = waterplanten_annotations[\"class\"]\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "    waterplanten_annotations  = waterplanten_annotations.to_crs(\"EPSG:28992\")\n",
        "\n",
        "    \n",
        "    with rasterio.open(tif_file) as dataset:\n",
        "         dfs += [extract_dataframe_pixels_values_from_tif_and_polygons(dataset, waterplanten_annotations, tif_file.split(\"/\")[-1], name_tif_file )]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.concat(dfs)\n",
        "#TODO: Height variable name is not correct\n",
        "#df['ndwi'] =df['height']\n",
        "#df = df.drop(['height'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['label'] = df['label'].replace(\"Waterplanten\", \"Waterplants\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.drop([\"image\",\"season\",\"annotation_no\", \"date\"], axis=1).groupby([\"label\"]).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_parquet(\"./annotations_pixel_dataframes/Superview_waterplanten_annotations.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload annotations to the cloud\n",
        "upload_to_blob(\"./annotations_pixel_dataframes/Superview_waterplanten_annotations.parquet\", \"Schippersgat/\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.12 ('remote_sensing_voorspelingen')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "2cb1ec6dcd5a6ab2905b154621f89ae3ac2e76c5c8088d5b9b78b98be99de6d3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
